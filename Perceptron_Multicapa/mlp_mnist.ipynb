{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practica 1: Perceptrón Multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mally Samira Hernandez Martinez | Código: 220286113 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingenieria de computacion (INCO) | Seccion D05 I7041\n",
    "Seminario de Solucion de Problemas de Inteligencia Artificial II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar librerías y Cargar los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Desactivar advertencias\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Fijar semilla para reproducibilidad\n",
    "np.random.seed(10)\n",
    "\n",
    "# Mostrar los archivos de la carpeta 'MNIST'\n",
    "for dirname, _, filenames in os.walk('MNIST'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar y visualizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df_train = pd.read_csv('MNIST/train.csv')\n",
    "df_test = pd.read_csv('MNIST/test.csv')\n",
    "\n",
    "# Mostrar el tamaño de los datasets\n",
    "print(\"Tamaño del dataset de entrenamiento:\", df_train.shape)\n",
    "print(\"Tamaño del dataset de prueba:\", df_test.shape)\n",
    "\n",
    "# Mostrar las primeras filas del conjunto de entrenamiento\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar las etiquetas de las imágenes\n",
    "x = df_train.drop(columns='label')\n",
    "y = df_train['label']\n",
    "\n",
    "# Normalizar los datos dividiendo por 255\n",
    "x = x / 255.0\n",
    "x_test = df_test / 255.0\n",
    "\n",
    "# Dividir el conjunto de entrenamiento en entrenamiento y validación\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Mostrar el tamaño de los conjuntos\n",
    "print(\"Tamaño de x_train:\", x_train.shape)\n",
    "print(\"Tamaño de x_val:\", x_val.shape)\n",
    "print(\"Tamaño de y_train:\", y_train.shape)\n",
    "print(\"Tamaño de y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de un dígito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar la imagen del primer dígito del conjunto de entrenamiento\n",
    "plt.imshow(x_train.to_numpy()[0].reshape(28,28))\n",
    "plt.title(f\"Dígito: {y.iloc[0]}\")  # Usamos la etiqueta original antes de la conversión a one-hot\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Obtener el primer dígito de x_train y su correspondiente etiqueta\n",
    "first_image = x_train.iloc[0].to_numpy().reshape(28, 28) * 255  # Se multiplica por 255 para volver a los valores originales\n",
    "first_label = y.iloc[0]  # Obtener la etiqueta original directamente del DataFrame antes del one-hot\n",
    "\n",
    "# Crear la figura con un tamaño mayor para mejor visualización\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.imshow(first_image, cmap='gray')  # Mostrar la imagen en escala de grises\n",
    "plt.title(f\"Dígito: {first_label}\", fontsize=18)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Añadir los valores de los píxeles en cada celda\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        pixel_value = int(first_image[i, j])  # Convertir a entero\n",
    "        # Si el píxel es muy claro (cercano a blanco), usar texto negro, sino usar texto blanco\n",
    "        text_color = 'black' if pixel_value > 200 else 'white'\n",
    "        plt.text(j, i, str(pixel_value), ha='center', va='center', color=text_color, \n",
    "                 fontsize=9, bbox=dict(facecolor='none', edgecolor='none'))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Mostrar un histograma de los valores de los píxeles\n",
    "plt.figure(figsize=(6, 4))\n",
    "# Reducimos los bins para aumentar el grosor de las barras\n",
    "plt.hist(first_image.flatten(), bins=10, color='brown', alpha=1.0) \n",
    "plt.title(f\"Histograma de los valores de los píxeles (Dígito: {first_label})\")\n",
    "plt.xlabel('Valor del píxel')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xticks(np.arange(0, 256, 25)) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encoding de las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las etiquetas a formato categórico (one-hot encoding)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_val = keras.utils.to_categorical(y_val, 10)\n",
    "\n",
    "print(\"Forma de y_train (one-hot):\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definicion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo MLP\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Agregar capas ocultas\n",
    "model.add(keras.layers.Dense(128, activation='relu', input_shape=(784,)))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Capa de salida con 10 neuronas y softmax\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Mostrar un resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val), verbose=0)\n",
    "\n",
    "# Imprimir las claves de las métricas guardadas\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficar la precisión y la pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la precisión\n",
    "plt.plot(history.history['accuracy'], label='Precisión (Entrenamiento)')\n",
    "plt.plot(history.history['val_accuracy'], label='Precisión (Validación)')\n",
    "plt.title('Precisión del Modelo')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Graficar la pérdida\n",
    "plt.plot(history.history['loss'], label='Pérdida (Entrenamiento)')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida (Validación)')\n",
    "plt.title('Pérdida del Modelo')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación del modelo en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_pred = model.predict(x_test)\n",
    "print(np.argmax(y_pred, axis=1)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en los datos de validación\n",
    "y_pred = model.predict(x_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# Graficar la matriz de confusión\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.ylabel('Etiqueta verdadera')\n",
    "plt.xlabel('Etiqueta predicha')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
